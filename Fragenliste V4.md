## Versuch 4 - Naive Bayes

1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training f칲r die sp칛tere Klassifikation abgespeichert werden?

(Siehe ipynb (Versuch_DocumentClassification(1).ipynb))

2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein? 

(Siehe ipynb (Versuch_DocumentClassification(1).ipynb))

3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tats칛chlich gegeben? 

(Siehe ipynb (Versuch_DocumentClassification(1).ipynb))

4. \[Bild von Formeln des Naive Bayes Classifiers\] Betrachten Sie die Formeln f칲r die Berechnung von 洧녞(洧냨|洧냥) und 洧녞(洧냣|洧냥). Welches Problem stellt sich ein, wenn in der Menge 洧녥(洧냥) ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie 洧냨 vorkommt und ein anderes Wort aus 洧녥(洧냥) nicht in den Trainingsdaten der Kategorie 洧냣 enthalten ist? Wie k칬nnte dieses Problem gel칬st werden?
(Siehe ipynb (Versuch_DocumentClassification(1).ipynb))

(Siehe ipynb (Versuch_DocumentClassification(1).ipynb))

5. \[Code einer einfachen `getwords()`\-Methode\] 

Wie k칬nnte die Klassifikationsg칲te durch Modifikation der `getwords()`\-Methode verbessert werden?
Siehe

(Siehe ipynb (Versuch_DocumentClassification(1).ipynb)) -> Siehe ganz unten

6. \[Bild der bedingten Wahrscheinlichkeiten und a-priori Wahrscheinlichkeiten\] 

F칲r einen Beispielsatz erhalten Sie die bedingten sowie die a-priori Wahrscheinlichkeiten. Berechnen Sie f칲r die gegebenen Wahrscheinlichkeiten die dazu geh칬rige Klasse?
(Siehe ipynb (Versuch_DocumentClassification(1).ipynb)) -> Siehe Test Abteil

7. \[Bild einer Confusion Matrix\] Gegeben ist ein Bild einer Confusion Matrix. Berechnen Sie f칲r die gegebenen Werte die Accuracy (Recall, Precision). Schreiben Sie daf칲r erst die Formel auf und berechnen Sie diese dann.
(Siehe ipynb (Versuch_DocumentClassification(1).ipynb)) -> Letze Aufgabe

8. Beschreiben Sie in Worten was die Accuracy-Metrik (oder Recall und Precision) aussagt bzw. wie diese zu interpretieren ist?
- Accuracy misst den Anteil korrekt klassifizierter Beispiele an allen Beispielen.
- Precision ist der Anteil korrekt positiver Vorhersagen an allen positiven Vorhersagen.
- Recall ist der Anteil korrekt positiver Vorhersagen an allen tats칛chlich positiven F칛llen.
- F1 Score: Der F1-Score fasst Precision und Recall zu einer Zahl zusammen und misst so die Balance zwischen Genauigkeit und Vollst칛ndigkeit bzw. es ist eine Bewertung wie gut ein Modell ist.